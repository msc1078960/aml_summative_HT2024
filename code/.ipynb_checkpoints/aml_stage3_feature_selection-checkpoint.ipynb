{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce78a17-659a-49e7-bc48-307c2ffeec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, pickle, functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data_dir = os.pardir + '/data/'\n",
    "out_dir = os.pardir + '/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc656e2-e390-441e-b911-49826f669501",
   "metadata": {},
   "source": [
    "## Stage 3: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6ebdee-85a3-415a-ab88-0f9e675f6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from Stage 2 and raw data files\n",
    "features = pd.read_csv(data_dir+'features.csv')\n",
    "x_train_simple = pd.read_csv(data_dir+'x_train_simpleImputed.csv', index_col='challengeID')\n",
    "x_train_knn = pd.read_csv(data_dir+'x_train_knnImputed.csv', index_col='challengeID')\n",
    "y = pd.read_csv(data_dir+'FFChallenge_v5/train.csv', index_col='challengeID')\n",
    "y_train = y.loc[x_train_simple.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd669d-e7a1-4158-94a9-3622183bf385",
   "metadata": {},
   "source": [
    "### 3.1 Feature Selection with Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59385aca-abfc-49bb-ba5e-f8d81d523139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting best k features for eviction\n",
      "Selecting best k features for layoff\n",
      "Selecting best k features for jobTraining\n",
      "Selecting best k features for materialHardship\n",
      "Selecting best k features for gpa\n",
      "Selecting best k features for grit\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_mi(train_x, train_y, outcomes, mutual_info_func, range_of_k):\n",
    "    '''\n",
    "    Given train_x, train_y, list of outcomes, mutual information function and a range of values for k,\n",
    "    select the best k features for each outcome based on mutual_info_func.\n",
    "    Returns a dictionary of each outcome as key and the value as a nested dictionary\n",
    "    of k as key and the value as the list of names of the best k selected features\n",
    "    '''\n",
    "    outcome_best_k_dict = {}\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        outcome_best_k_dict[outcome] = {}\n",
    "        print(f\"Selecting best k features for {outcome}\")\n",
    "\n",
    "        for k in range_of_k:\n",
    "            y = train_y[outcome].dropna()\n",
    "            x = train_x.loc[y.index.values]\n",
    "            X = SelectKBest(mutual_info_func, k=k).fit(x,y)\n",
    "            mask = X.get_support()\n",
    "            feature_names = x.columns[mask]\n",
    "            outcome_best_k_dict[outcome][k] = feature_names\n",
    "\n",
    "    return outcome_best_k_dict\n",
    "\n",
    "range_of_k = [50, 100, 250, 500, 1000, 2000]\n",
    "\n",
    "# Binary variables\n",
    "outcome_best_k_simple = feature_selection_mi(x_train_simple, y_train, ['eviction', 'layoff', 'jobTraining'], \n",
    "                                    mutual_info_classif, range_of_k)\n",
    "outcome_best_k_knn = feature_selection_mi(x_train_knn, y_train, ['eviction', 'layoff', 'jobTraining'],\n",
    "                                    mutual_info_classif, range_of_k)\n",
    "# Continuous variables\n",
    "outcome_best_k2_simple = feature_selection_mi(x_train_simple, y_train, ['materialHardship', 'gpa', 'grit'],\n",
    "                                    mutual_info_regression, range_of_k)\n",
    "outcome_best_k2_knn = feature_selection_mi(x_train_knn, y_train, ['materialHardship', 'gpa', 'grit'],\n",
    "                                    mutual_info_regression, range_of_k)\n",
    "\n",
    "outcome_best_k_simple.update(outcome_best_k2_simple)\n",
    "outcome_best_k_knn.update(outcome_best_k2_knn)\n",
    "\n",
    "# Save selected features\n",
    "# with open(data_dir+'outcome_best_k.pkl', 'wb') as f:\n",
    "#     pickle.dump(outcome_best_k_simple, f)\n",
    "\n",
    "# with open(data_dir+'outcome_best_k_knn.pkl', 'wb') as f:\n",
    "#     pickle.dump(outcome_best_k_knn, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5abc9-d36b-4ac2-ba48-22eeecfeb3a1",
   "metadata": {},
   "source": [
    "### 3.2 Feature Selection with LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c46b7e-a97b-4531-afa3-7f13e1cafee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_lasso(train_x, train_y):\n",
    "    '''\n",
    "    Given train_x, train_y, list of outcomes, mutual information function and a range of values for k,\n",
    "    select the best k features for each outcome using LASSO (non-zero lasso coefficient estimates).\n",
    "    Returns a dictionary of each outcome as key and the value as a nested dictionary\n",
    "    of k as key and the value as the list of names of the best k selected features\n",
    "    '''\n",
    "    outcomes = ['gpa', 'grit', 'materialHardship', 'eviction', 'layoff', 'jobTraining']\n",
    "    outcome_alpha_feature = {}\n",
    "\n",
    "    r2_target = 0.5 # R2 target is set based on literature review\n",
    "    alphas = np.logspace(-2,1,20).tolist()\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        print(f\"\\nSelecting features for {outcome}\")\n",
    "        outcome_alpha_feature[outcome] = {}\n",
    "        y = y_train[outcome].dropna()\n",
    "        X = train_x.loc[y.index.values]\n",
    "        r_2 = []\n",
    "        for a in alphas:\n",
    "            reg = linear_model.Lasso(alpha = a)\n",
    "            reg.fit(X,y)\n",
    "            r_2.append(reg.score(X,y))\n",
    "\n",
    "        reg = linear_model.Lasso()\n",
    "        path = reg.path(X,y, alphas = alphas)\n",
    "        n = [np.sum(path[1][:,n] != 0) for n in range(0,len(alphas))]\n",
    "        r_2.reverse()\n",
    "        alphas.reverse()\n",
    "\n",
    "        temp = [abs(i-r2_target) for i in r_2]\n",
    "        alpha_0 = alphas[temp.index(min(temp))]\n",
    "        r2 = r_2[temp.index(min(temp))]\n",
    "        outcome_alpha_feature[outcome]['alpha'] = alpha_0\n",
    "        outcome_alpha_feature[outcome]['r2'] = r2\n",
    "\n",
    "        coeff = pd.DataFrame(path[1][:,temp.index(min(temp))],index = X.columns.values)\n",
    "        feature_index = coeff != 0\n",
    "        selected_features = X.loc[:,feature_index.iloc[:,0]]\n",
    "        x_lars = selected_features.columns.values\n",
    "        outcome_alpha_feature[outcome]['features'] = x_lars\n",
    "    \n",
    "    return outcome_alpha_feature\n",
    "\n",
    "# Save selected features for knn-imputed train\n",
    "lasso_outcome_alpha_feature_knn_dict = feature_selection_lasso(x_train_knn, y_train)\n",
    "# with open(data_dir+'lasso_outcome_alpha_feature_knn_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(lasso_outcome_alpha_feature_knn_dict, f)\n",
    "\n",
    "# Save selected features for simple-imputed train\n",
    "lasso_outcome_alpha_feature_dict = feature_selection_lasso(x_train_simple, y_train)\n",
    "# with open(data_dir+'lasso_outcome_alpha_feature_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(lasso_outcome_alpha_feature_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
