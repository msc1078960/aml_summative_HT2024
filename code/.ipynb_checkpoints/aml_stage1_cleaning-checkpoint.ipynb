{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572a8761-14af-4769-9921-a1330d9b287c",
   "metadata": {},
   "source": [
    "## Applied ML Summative Stage 1: Data Cleaning and Identifying Variable Types\n",
    "\n",
    "<mark>**All code and data files needed to reproduce the results in the submission by candidate 1078960 are hosted on this anonymous Github repository: <a></a>. This notebook contains only the code.**</mark>\n",
    "\n",
    "This notebook is organised as follows:\n",
    "\n",
    "##### TOC (workflow):\n",
    "- ##### Stage 1: Data Cleaning\n",
    "- ##### Stage 2: Data Imputation\n",
    "- ##### Stage 3: Feature Selection\n",
    "- ##### Stage 4: Model Building (In-Sample)\n",
    "- ##### Stage 5: Model Evaluation (Out-of-Sample)\n",
    "<!-- - `background_reduced_withMissingCodes.csv`: same as `background_reduced` but with original FFC missing codes preserved\n",
    "- `bg_reduced_categorical_withMissingCodes.csv`: background file containing only categorical features, with zero-variance and high-missingness variables removed\n",
    "- `bg_reduced_continuous_withMissingCodes.csv`: background file containing only continuous features, with zero-variance and high-missingness variables removed -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b447f24-c6e9-475b-a006-d74100b2f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = os.pardir + '/data/'\n",
    "out_dir = os.pardir + '/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7a5a3-3dc7-4ce9-b5d3-23b1e2a973aa",
   "metadata": {},
   "source": [
    "## Stage 1: Data Cleaning\n",
    "\n",
    "Input:\n",
    "- `background.csv`: original file containing 4,242 rows (one per family) and 13,027 columnsâ€”background variables asked from birth to age 9\n",
    "- `FFMetadata_v13_UTF.csv`: latest variable metadata file released by FFC (https://metadata.ffcws.princeton.edu/about)\n",
    "\n",
    "Output:\n",
    "- `background_cleaned.csv`: background file with zero-variance and high-missingness variables removed, and one-hot encodings for all categorical variables as well as indicators for missing responses due to \"don't know\" and \"refuse\"\n",
    "- `features.csv`: features metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8153e7e5-c28a-4732-b8d1-df1057de2257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background file has initial dimensions: (4242, 13026)\n"
     ]
    }
   ],
   "source": [
    "## Load background data from FFC\n",
    "bg = pd.read_csv(data_dir+'FFChallenge_v5/background.csv', index_col='challengeID', low_memory=False)\n",
    "print(f\"Background file has initial dimensions: {bg.shape}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889eee0-db69-45aa-9f85-c50030a53a9b",
   "metadata": {},
   "source": [
    "### 1.1 Remove columns with > 80% missing data and columns with zero variance or < 0.05 standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ca414c0-4882-472b-be1d-16a692443ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2432 (19.0% of initial number of features) constant variables, leaving 10594 variables\n",
      "Removed 5449 (42.0 % of initial number of features) variables with > 80% missing data or < 0.05 standard deviation, leaving 5145 variables\n"
     ]
    }
   ],
   "source": [
    "## Create copy to preserve Missing Codes\n",
    "bg_reduced = bg.copy()\n",
    "\n",
    "## Replace missing codes with NaN\n",
    "bg_reduced.replace({\n",
    "    -1: np.NaN, -2: np.NaN, -3: np.NaN,\n",
    "    -4: np.NaN, -5: np.NaN, -6: np.NaN, \n",
    "    -7: np.NaN, -8: np.NaN, -9: np.NaN, \n",
    "    np.inf: np.NaN, -np.inf: np.NaN\n",
    "}, inplace=True)\n",
    "\n",
    "bg_reduced.replace(\"Missing\", np.NaN, inplace=True)\n",
    "\n",
    "constant_lst = pd.read_csv(data_dir+'FFChallenge_v5/constantVariables.txt', header=None)\n",
    "constant_lst.columns = ['constant_var']\n",
    "bg_reduced.drop(columns = constant_lst['constant_var'], inplace=True)\n",
    "print(f\"Removed {bg.shape[1] - bg_reduced.shape[1]} ({round((bg.shape[1] - bg_reduced.shape[1])/bg.shape[1],2)*100}% of initial number of features) constant variables, leaving {bg_reduced.shape[1]} variables\")\n",
    "\n",
    "variables = bg_reduced.columns\n",
    "\n",
    "for var in variables:\n",
    "    if sum(pd.isnull(bg_reduced[var])) > bg_reduced.shape[0] * 0.8:\n",
    "        bg_reduced.drop(var, axis=1, inplace=True) \n",
    "\n",
    "std = bg_reduced.std(axis=0, numeric_only=True)\n",
    "std = std.where(std < 0.05).isna()\n",
    "bg_reduced = bg_reduced[std.index[std]]\n",
    "\n",
    "print(f\"Removed {len(variables) - bg_reduced.shape[1]} ({round((len(variables) - bg_reduced.shape[1]) / bg.shape[1], 2)*100} % of initial number of features) variables with > 80% missing data or < 0.05 standard deviation, leaving {bg_reduced.shape[1]} variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c554bca-eb7f-41ca-90d0-67312af30d46",
   "metadata": {},
   "source": [
    "### 1.2 Identify continuous, categorical and ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6a8bd3-8a70-4f2c-b14c-94f4b28ba610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest FFC metadata file (https://metadata.ffcws.princeton.edu/about), \n",
      "we have identified 5088 variables: 646 continuous, 2584 categorical, 1858 ordinal, and 57 unknown variables.\n",
      "\n",
      "After identifying the unknown variables based on heuristics, \n",
      "we have 5145 variables: 681 continuous, 2606 categorical, 1858 ordinal, and 0 unknown variables.\n"
     ]
    }
   ],
   "source": [
    "# Load reduced background and FFC metadata files\n",
    "bg = bg[bg_reduced.columns]\n",
    "meta = pd.read_csv(data_dir + 'FFMetadata_v13_UTF.csv', low_memory=False)\n",
    "\n",
    "meta = meta[['new_name', 'varlab', 'type']]\n",
    "meta['type'] = meta['type'].apply(lambda x: str(x))\n",
    "meta = meta[meta.type.isin(['Binary', 'Unordered Categorical', 'Ordered Categorical', 'Continuous'])]\n",
    "meta.columns = ['variable', 'label', 'type']\n",
    "meta['type'] = meta['type'].apply(lambda x: 'Unordered Categorical' if x == 'Binary' else x)\n",
    "\n",
    "features = meta[meta['variable'].isin(bg.columns)].copy()\n",
    "print(f\"Using the latest FFC metadata file (https://metadata.ffcws.princeton.edu/about), \\nwe have identified {features.shape[0]} variables: {features[features['type']=='Continuous'].shape[0]} continuous, {features[features['type']=='Unordered Categorical'].shape[0]} categorical, {features[features['type']=='Ordered Categorical'].shape[0]} ordinal, and {len(set(bg.columns) - set(features['variable']))} unknown variables.\")\n",
    "\n",
    "# Some background variables were not documented in metadata file; label the types of these unknown variables based on a few heuristics\n",
    "unknown_vars =  set(bg.columns) - set(features.variable)\n",
    "unknown_vars = list(unknown_vars)\n",
    "\n",
    "pattern = re.compile(r'(how.*?(?:is|many|often|much|long))|rate|frequency|number|#|level|highest|amount|days|total|scale|times', re.IGNORECASE)\n",
    "\n",
    "for var in unknown_vars:\n",
    "    ## Heuristic 1: More than 15 Unique Answers -> continuous\n",
    "    if bg[var].nunique() > 15:\n",
    "        features.loc[len(features.index)] = [var, np.NaN, 'Continuous']\n",
    "        \n",
    "    ## Heuristic 2: Identify ordinal variables using common keywords in ordinal question, similar to Rigobon et al. (2019)        \n",
    "    elif bool(pattern.search(var)):\n",
    "        features.loc[len(features.index)] = [var, np.NaN, 'Ordered Categorical']\n",
    "        \n",
    "    ## Heuristic 3: Other unknowns are assumed to be categorical\n",
    "    else:\n",
    "        features.loc[len(features.index)] = [var, np.NaN, 'Unordered Categorical']\n",
    "    \n",
    "print(f\"\\nAfter identifying the unknown variables based on heuristics, \\nwe have {features.shape[0]} variables: {features[features['type']=='Continuous'].shape[0]} continuous, {features[features['type']=='Unordered Categorical'].shape[0]} categorical, {features[features['type']=='Ordered Categorical'].shape[0]} ordinal, and {features[features['type']=='unknown'].shape[0]} unknown variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d508131-7fae-4c2f-8402-e2125888df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding indicator variables for 'refuse' and 'dont know' missing responses, we have a total of 5147 features.\n"
     ]
    }
   ],
   "source": [
    "# Add indicator variables for \"Refuse to Answer\" or \"Don't Know\" missing responses for ordinal and continuous variables\n",
    "df_refuse_dontknow = bg.copy()\n",
    "\n",
    "df_refuse_dontknow['refuse_check'] = df_refuse_dontknow.where(df_refuse_dontknow == -1, other=0, axis=0).sum(axis=1) \n",
    "df_refuse_dontknow['refuse'] = df_refuse_dontknow['refuse_check'].apply(lambda x: 1 if x < 0 else 0)\n",
    "\n",
    "df_refuse_dontknow['dontknow_check'] = df_refuse_dontknow.where(df_refuse_dontknow == -2, other=0, axis=0).sum(axis=1) \n",
    "df_refuse_dontknow['dontknow'] = df_refuse_dontknow['dontknow_check'].apply(lambda x: 1 if x < 0 else 0)\n",
    "df_refuse_dontknow = df_refuse_dontknow[['refuse', 'dontknow']]\n",
    "\n",
    "bg_encoded = bg.merge(df_refuse_dontknow, left_index=True, right_index=True)\n",
    "\n",
    "features = pd.concat([features, pd.DataFrame({\n",
    "            'variable': ['dontknow', 'refuse'],\n",
    "            'label': ['Dont Know', 'Refuse'],\n",
    "            'type': ['Unordered Categorical', 'Unordered Categorical']\n",
    "        })])\n",
    "\n",
    "print(f\"After adding indicator variables for 'refuse' and 'dont know' missing responses, we have a total of {bg_encoded.shape[1]} features.\")\n",
    "\n",
    "bg_encoded.replace({\n",
    "    -1: np.NaN, -2: np.NaN, -3: np.NaN, \n",
    "    -4: np.NaN, -5: np.NaN, -6: np.NaN, \n",
    "    -7: np.NaN, -8: np.NaN, -9: np.NaN, \n",
    "    np.inf: np.NaN, -np.inf: np.NaN\n",
    "}, inplace=True)\n",
    "\n",
    "bg_encoded.to_csv(data_dir + 'background_cleaned.csv')\n",
    "features.to_csv(data_dir + 'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934bda5-a000-4c89-8291-3aa8d19897b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical features from variable metadata\n",
    "\n",
    "## Load variable metadata provided by FFC\n",
    "meta = pd.read_csv(data_dir + 'ffc_variable_types.csv')\n",
    "bg = pd.read_csv(data_dir + 'background_reduced_withMissingCodes.csv')\n",
    "\n",
    "np.random.seed(0)\n",
    "meta['label'] = meta['label'].apply(lambda x: str(x))\n",
    "\n",
    "## Features after removing based on missing-ness and low variance\n",
    "features = meta[meta['variable'].isin(bg.columns)].drop(0)\n",
    "\n",
    "## More than 15 Unique Answers -> continuous\n",
    "features.loc[(features['unique_values'] > 15), 'variable_type'] = 'continuous'\n",
    "\n",
    "## Identify ordinal variables using keywords\n",
    "pattern = re.compile(r'(how.*?(?:is|many|often|much|long))|rate|frequency|number|#|level|highest|amount|days|total|scale|times', re.IGNORECASE)\n",
    "matches = features['label'].apply(lambda x: bool(pattern.search(x)))\n",
    "features.loc[(matches) & (features['variable_type'] != 'continuous'), 'variable_type'] = 'Ordered Categorical'\n",
    "\n",
    "## Other unknowns are assumed to be categorical\n",
    "\n",
    "features.loc[features['variable_type'] == 'unknown', 'variable_type'] = 'categorical'\n",
    "\n",
    "print(f\"Out of {features.shape[0]} variables, identified {features[features['variable_type']=='continuous'].shape[0]} continuous, {features[features['variable_type']=='categorical'].shape[0]} categorical, {features[features['variable_type']=='ordinal'].shape[0]} ordinal variables, leaving {features[features['variable_type']=='unknown'].shape[0]} unknown variables.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
